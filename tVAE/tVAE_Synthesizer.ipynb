{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.upload()      # Upload the training data csv. The following implementation drops the null values. Custom handling before uploading is encouraged\n",
        "dataset_name = '...'      # use the name .csv file imported above\n",
        "attributes_to_ignore = []     # attributes with unique values such as names and ids that dont hold any information for the data and make learning harder\n",
        "discrete_columns = []"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zaR-1PAVeeHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(dataset_name)\n",
        "train_data = train_data.dropna()\n",
        "train_data = train_data.drop(attributes_to_ignore, axis = 1)\n",
        "train_data.head()"
      ],
      "metadata": {
        "id": "5mJPsRGKc_Xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#upload the 'transformer.py' and 'data_sampler.py'\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "NPP0J4lzI5YQ",
        "outputId": "7a15201d-8f56-4310-d3aa-cba65d2fd259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da3a8851-286b-483d-8b5d-dfc9ae60070d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da3a8851-286b-483d-8b5d-dfc9ae60070d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data_sampler.py to data_sampler.py\n",
            "Saving transformer.py to transformer.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'data_sampler.py': b'# -*- coding: utf-8 -*-\\n\"\"\"CTGAN_data_sampler.ipynb\\n\\nAutomatically generated by Colab.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1Nx032G5WjTNIKe6Nuly8E-31Xj3xzOWG\\n\"\"\"\\n\\n\"\"\"DataSampler module.\"\"\"\\n\\nimport numpy as np\\n\\n\\nclass DataSampler(object):\\n    \"\"\"DataSampler samples the conditional vector and corresponding data for CTGAN.\"\"\"\\n\\n    def __init__(self, data, output_info, log_frequency):\\n        self._data_length = len(data)\\n\\n        def is_discrete_column(column_info):\\n            return len(column_info) == 1 and column_info[0].activation_fn == \\'softmax\\'\\n\\n        n_discrete_columns = sum([\\n            1 for column_info in output_info if is_discrete_column(column_info)\\n        ])\\n\\n        self._discrete_column_matrix_st = np.zeros(n_discrete_columns, dtype=\\'int32\\')\\n\\n        # Store the row id for each category in each discrete column.\\n        # For example _rid_by_cat_cols[a][b] is a list of all rows with the\\n        # a-th discrete column equal value b.\\n        self._rid_by_cat_cols = []\\n\\n        # Compute _rid_by_cat_cols\\n        st = 0\\n        for column_info in output_info:\\n            if is_discrete_column(column_info):\\n                span_info = column_info[0]\\n                ed = st + span_info.dim  #span_info.dim is the number of categories of the discrete column\\n\\n                rid_by_cat = []\\n                for j in range(span_info.dim):  #For each category\\n                    rid_by_cat.append(np.nonzero(data[:, st + j])[0]) #np.nonzero returns the indices that correspond to nonzero values.\\n                self._rid_by_cat_cols.append(rid_by_cat) #So for every category a list of indices is created that matches the rows that belong in it. In the end we get a concatenation of these lists.\\n                #For each different column (meaning column_info in output_info as the latter contains info about all the columns) a rid_by_cat is created and the appended to _rid_by_cat_cols\\n                #So the ed result is a 2-D array where _rid_by_cat_cols[a][b] is a list of all rows with the a-th discrete column equal to value b\\n                st = ed\\n            else:\\n                st += sum([span_info.dim for span_info in column_info])\\n        assert st == data.shape[1]\\n\\n        # Prepare an interval matrix for efficiently sample conditional vector\\n        max_category = max(\\n            [column_info[0].dim for column_info in output_info if is_discrete_column(column_info)],\\n            default=0,\\n        )\\n\\n        self._discrete_column_cond_st = np.zeros(n_discrete_columns, dtype=\\'int32\\')\\n        self._discrete_column_n_category = np.zeros(n_discrete_columns, dtype=\\'int32\\')\\n        self._discrete_column_category_prob = np.zeros((n_discrete_columns, max_category))\\n        self._n_discrete_columns = n_discrete_columns\\n        self._n_categories = sum([\\n            column_info[0].dim for column_info in output_info if is_discrete_column(column_info)\\n        ])\\n\\n        st = 0\\n        current_id = 0\\n        current_cond_st = 0\\n        for column_info in output_info:\\n            if is_discrete_column(column_info):\\n                span_info = column_info[0]\\n                ed = st + span_info.dim\\n                category_freq = np.sum(data[:, st:ed], axis=0) #sums the 1 values found in each category of the current attribute\\n                if log_frequency:\\n                    category_freq = np.log(category_freq + 1)\\n                category_prob = category_freq / np.sum(category_freq) #normalizes the values tfrom 0 to 1\\n                self._discrete_column_category_prob[current_id, : span_info.dim] = category_prob\\n                self._discrete_column_cond_st[current_id] = current_cond_st\\n                self._discrete_column_n_category[current_id] = span_info.dim\\n                current_cond_st += span_info.dim\\n                current_id += 1\\n                st = ed\\n            else:\\n                st += sum([span_info.dim for span_info in column_info])\\n\\n    #sample a random category from the attribute \\'discrete_column_id\\'\\n    def _random_choice_prob_index(self, discrete_column_id):\\n        probs = self._discrete_column_category_prob[discrete_column_id] #that is an array with 1 row and span_info.dim columns\\n        r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1) #returns basically one value with 2 dimensions to match probs\\n        return (probs.cumsum(axis=1) > r).argmax(axis=1) #cumsum is the cumulative sum. Every probability is added to the previous one and as we move forward, the first time the sum exceeds r, we select the corresponding column\\n\\n    def sample_condvec(self, batch):\\n        \"\"\"Generate the conditional vector for training.\\n\\n        Returns:\\n            cond (batch x #categories):\\n                The conditional vector.\\n            mask (batch x #discrete columns):\\n                A one-hot vector indicating the selected discrete column.\\n            discrete column id (batch):\\n                Integer representation of mask.\\n            category_id_in_col (batch):\\n                Selected category in the selected discrete column.\\n        \"\"\"\\n        if self._n_discrete_columns == 0:\\n            return None\\n\\n        discrete_column_id = np.random.choice(np.arange(self._n_discrete_columns), batch) #Samples randomly a total of \\'batch\\' column ids\\n\\n        cond = np.zeros((batch, self._n_categories), dtype=\\'float32\\')\\n        mask = np.zeros((batch, self._n_discrete_columns), dtype=\\'float32\\')\\n        mask[np.arange(batch), discrete_column_id] = 1 #For each row of the batch numbered for 0 to batch-1 it sets the corresponding column id to 1\\n        category_id_in_col = self._random_choice_prob_index(discrete_column_id)\\n        category_id = self._discrete_column_cond_st[discrete_column_id] + category_id_in_col\\n        cond[np.arange(batch), category_id] = 1\\n\\n        return cond, mask, discrete_column_id, category_id_in_col\\n        ## !!! Here mask vector seems to anly be dealing with the discrete columns and not also with the categories as described in the paper !!!\\n\\n    def sample_original_condvec(self, batch):\\n        \"\"\"Generate the conditional vector for generation use original frequency.\"\"\"\\n        if self._n_discrete_columns == 0:\\n            return None\\n\\n        category_freq = self._discrete_column_category_prob.flatten()\\n        category_freq = category_freq[category_freq != 0] # removes zero values\\n        category_freq = category_freq / np.sum(category_freq) #category_freq now contains the probability af each category of each colun all together normilized from 0 to 1\\n        col_idxs = np.random.choice(np.arange(len(category_freq)), batch, p=category_freq) #makes \\'batch\\' random choices based on category_freq distribution\\n        cond = np.zeros((batch, self._n_categories), dtype=\\'float32\\')\\n        cond[np.arange(batch), col_idxs] = 1\\n\\n        return cond\\n\\n    def sample_data(self, data, n, col, opt):\\n        \"\"\"Sample data from original training data satisfying the sampled conditional vector.\\n\\n        Args:\\n            data:\\n                The training data.\\n\\n        Returns:\\n            n:\\n                n rows of matrix data.\\n        \"\"\"\\n        ## col -> discrete_column_id\\n        ## opt -> category_id_in_col\\n        if col is None:\\n            idx = np.random.randint(len(data), size=n) #generates n random ints between 0 and len(data)\\n            return data[idx]\\n\\n        idx = []\\n        for c, o in zip(col, opt):\\n            idx.append(np.random.choice(self._rid_by_cat_cols[c][o])) #for all col,opt combinations given, return a row with the value opt in column col\\n\\n        return data[idx]\\n\\n    def dim_cond_vec(self):\\n        \"\"\"Return the total number of categories.\"\"\"\\n        return self._n_categories\\n\\n    def generate_cond_from_condition_column_info(self, condition_info, batch):\\n        \"\"\"Generate the condition vector.\"\"\"\\n        vec = np.zeros((batch, self._n_categories), dtype=\\'float32\\')\\n        id_ = self._discrete_column_matrix_st[condition_info[\\'discrete_column_id\\']] #condition_info comes from convert_column_name_value_to_id of the transformer module\\n        id_ += condition_info[\\'value_id\\']\\n        vec[:, id_] = 1\\n        return vec',\n",
              " 'transformer.py': b'# -*- coding: utf-8 -*-\\n\"\"\"CTGAN_Transformer.ipynb\\n\\nAutomatically generated by Colab.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1saeU9-5MYB9DK9JenugodWrN32_JFoMC\\n\"\"\"\\n\\n\"\"\"DataTransformer module.\"\"\"\\n\\nfrom collections import namedtuple\\n\\nimport numpy as np\\nimport pandas as pd\\nfrom joblib import Parallel, delayed\\nfrom rdt.transformers import ClusterBasedNormalizer, OneHotEncoder\\n\\nSpanInfo = namedtuple(\\'SpanInfo\\', [\\'dim\\', \\'activation_fn\\'])\\nColumnTransformInfo = namedtuple(\\n    \\'ColumnTransformInfo\\',\\n    [\\'column_name\\', \\'column_type\\', \\'transform\\', \\'output_info\\', \\'output_dimensions\\'],\\n)\\n\\n\\nclass DataTransformer(object):\\n    \"\"\"Data Transformer.\\n\\n    Model continuous columns with a BayesianGMM and normalize them to a scalar between [-1, 1]\\n    and a vector. Discrete columns are encoded using a OneHotEncoder.\\n    \"\"\"\\n\\n    def __init__(self, max_clusters=10, weight_threshold=0.005):\\n        \"\"\"Create a data transformer.\\n\\n        Args:\\n            max_clusters (int):\\n                Maximum number of Gaussian distributions in Bayesian GMM.\\n            weight_threshold (float):\\n                Weight threshold for a Gaussian distribution to be kept.\\n        \"\"\"\\n        self._max_clusters = max_clusters\\n        self._weight_threshold = weight_threshold\\n\\n    def _fit_continuous(self, data):\\n        \"\"\"Train Bayesian GMM for continuous columns.\\n\\n        Args:\\n            data (pd.DataFrame):\\n                A dataframe containing a column.\\n\\n        Returns:\\n            namedtuple:\\n                A ``ColumnTransformInfo`` object.\\n        \"\"\"\\n        column_name = data.columns[0]\\n        gm = ClusterBasedNormalizer(\\n            missing_value_generation=\\'from_column\\',\\n            max_clusters=min(len(data), self._max_clusters),\\n            weight_threshold=self._weight_threshold,\\n        )\\n        gm.fit(data, column_name)\\n        num_components = sum(gm.valid_component_indicator)\\n\\n        return ColumnTransformInfo(\\n            column_name=column_name,\\n            column_type=\\'continuous\\',\\n            transform=gm, #the gm transformer is kept in this namedtuple for later use\\n            output_info=[SpanInfo(1, \\'tanh\\'), SpanInfo(num_components, \\'softmax\\')],\\n            output_dimensions=1 + num_components,\\n        )\\n\\n    def _fit_discrete(self, data):\\n        \"\"\"Fit one hot encoder for discrete column.\\n\\n        Args:\\n            data (pd.DataFrame):\\n                A dataframe containing a column.\\n\\n        Returns:\\n            namedtuple:\\n                A ``ColumnTransformInfo`` object.\\n        \"\"\"\\n        column_name = data.columns[0]\\n        ohe = OneHotEncoder()\\n        ohe.fit(data, column_name) #the onehotencoder is fit on the column\\n        num_categories = len(ohe.dummies)\\n\\n        return ColumnTransformInfo(\\n            column_name=column_name,\\n            column_type=\\'discrete\\',\\n            transform=ohe, #the onehotencoder is kept in this namedtuple for later use\\n            output_info=[SpanInfo(num_categories, \\'softmax\\')],\\n            output_dimensions=num_categories,\\n        )\\n\\n    def fit(self, raw_data, discrete_columns=()):\\n        \"\"\"Fit the ``DataTransformer``.\\n\\n        Fits a ``ClusterBasedNormalizer`` for continuous columns and a\\n        ``OneHotEncoder`` for discrete columns.\\n\\n        This step also counts the #columns in matrix data and span information.\\n        \"\"\"\\n        self.output_info_list = []\\n        self.output_dimensions = 0\\n        self.dataframe = True\\n\\n        if not isinstance(raw_data, pd.DataFrame):\\n            self.dataframe = False\\n            # work around for RDT issue #328 Fitting with numerical column names fails\\n            discrete_columns = [str(column) for column in discrete_columns]\\n            column_names = [str(num) for num in range(raw_data.shape[1])]\\n            raw_data = pd.DataFrame(raw_data, columns=column_names)\\n\\n        self._column_raw_dtypes = raw_data.infer_objects().dtypes\\n        self._column_transform_info_list = []\\n        for column_name in raw_data.columns:\\n            if column_name in discrete_columns:\\n                column_transform_info = self._fit_discrete(raw_data[[column_name]]) #_fit_discrete fits a OneHotEncoder in column \\'column_name\\'\\n            else:\\n                column_transform_info = self._fit_continuous(raw_data[[column_name]]) #_fit_continuous fits a GMM in column \\'column_name\\'\\n\\n            self.output_info_list.append(column_transform_info.output_info)\\n            self.output_dimensions += column_transform_info.output_dimensions\\n            self._column_transform_info_list.append(column_transform_info)\\n\\n    def _transform_continuous(self, column_transform_info, data): #Applies the Cluster Based Normilizer\\n        column_name = data.columns[0]\\n        flattened_column = data[column_name].to_numpy().flatten()\\n        data = data.assign(**{column_name: flattened_column})\\n        gm = column_transform_info.transform\\n        transformed = gm.transform(data)\\n\\n        #  Converts the transformed data to the appropriate output format.\\n        #  The first column (ending in \\'.normalized\\') stays the same,\\n        #  but the lable encoded column (ending in \\'.component\\') is one hot encoded.\\n        output = np.zeros((len(transformed), column_transform_info.output_dimensions))\\n        output[:, 0] = transformed[f\\'{column_name}.normalized\\'].to_numpy()\\n        index = transformed[f\\'{column_name}.component\\'].to_numpy().astype(int)\\n        output[np.arange(index.size), index + 1] = 1.0\\n\\n        return output\\n\\n    def _transform_discrete(self, column_transform_info, data): #Takes the OneHotEncoder from ColumnTransformInfo that was fit on the column and applies it to it\\n        ohe = column_transform_info.transform\\n        return ohe.transform(data).to_numpy()\\n\\n    def _synchronous_transform(self, raw_data, column_transform_info_list):\\n        \"\"\"Take a Pandas DataFrame and transform columns synchronous.\\n\\n        Outputs a list with Numpy arrays.\\n        \"\"\"\\n        column_data_list = []\\n        for column_transform_info in column_transform_info_list:\\n            column_name = column_transform_info.column_name\\n            data = raw_data[[column_name]]\\n            if column_transform_info.column_type == \\'continuous\\':\\n                column_data_list.append(self._transform_continuous(column_transform_info, data))\\n            else:\\n                column_data_list.append(self._transform_discrete(column_transform_info, data))\\n\\n        return column_data_list\\n\\n    def _parallel_transform(self, raw_data, column_transform_info_list):\\n        \"\"\"Take a Pandas DataFrame and transform columns in parallel.\\n\\n        Outputs a list with Numpy arrays.\\n        \"\"\"\\n        processes = []\\n        for column_transform_info in column_transform_info_list:\\n            column_name = column_transform_info.column_name\\n            data = raw_data[[column_name]]\\n            process = None\\n            if column_transform_info.column_type == \\'continuous\\':\\n                process = delayed(self._transform_continuous)(column_transform_info, data)\\n            else:\\n                process = delayed(self._transform_discrete)(column_transform_info, data)\\n            processes.append(process)\\n\\n        return Parallel(n_jobs=-1)(processes)\\n\\n    def transform(self, raw_data): #Here, _transform_discrete or _tranform_continuous is called through synchronous or parallel transform\\n        \"\"\"Take raw data and output a matrix data.\"\"\"\\n        if not isinstance(raw_data, pd.DataFrame):\\n            column_names = [str(num) for num in range(raw_data.shape[1])]\\n            raw_data = pd.DataFrame(raw_data, columns=column_names)\\n\\n        # Only use parallelization with larger data sizes.\\n        # Otherwise, the transformation will be slower.\\n        if raw_data.shape[0] < 500:\\n            column_data_list = self._synchronous_transform(\\n                raw_data, self._column_transform_info_list\\n            )\\n        else:\\n            column_data_list = self._parallel_transform(raw_data, self._column_transform_info_list)\\n\\n        return np.concatenate(column_data_list, axis=1).astype(float)\\n\\n    def _inverse_transform_continuous(self, column_transform_info, column_data, sigmas, st):\\n        gm = column_transform_info.transform\\n        data = pd.DataFrame(column_data[:, :2], columns=list(gm.get_output_sdtypes())).astype(float)\\n        data[data.columns[1]] = np.argmax(column_data[:, 1:], axis=1)\\n        if sigmas is not None:\\n            selected_normalized_value = np.random.normal(data.iloc[:, 0], sigmas[st])\\n            data.iloc[:, 0] = selected_normalized_value\\n\\n        return gm.reverse_transform(data)\\n\\n    def _inverse_transform_discrete(self, column_transform_info, column_data):\\n        ohe = column_transform_info.transform\\n        data = pd.DataFrame(column_data, columns=list(ohe.get_output_sdtypes()))\\n        return ohe.reverse_transform(data)[column_transform_info.column_name]\\n\\n    def inverse_transform(self, data, sigmas=None):\\n        \"\"\"Take matrix data and output raw data.\\n\\n        Output uses the same type as input to the transform function.\\n        Either np array or pd dataframe.\\n        \"\"\"\\n        st = 0\\n        recovered_column_data_list = []\\n        column_names = []\\n        for column_transform_info in self._column_transform_info_list:\\n            dim = column_transform_info.output_dimensions\\n            column_data = data[:, st : st + dim]\\n            if column_transform_info.column_type == \\'continuous\\':\\n                recovered_column_data = self._inverse_transform_continuous(\\n                    column_transform_info, column_data, sigmas, st\\n                )\\n            else:\\n                recovered_column_data = self._inverse_transform_discrete(\\n                    column_transform_info, column_data\\n                )\\n\\n            recovered_column_data_list.append(recovered_column_data)\\n            column_names.append(column_transform_info.column_name)\\n            st += dim\\n\\n        recovered_data = np.column_stack(recovered_column_data_list)\\n        recovered_data = pd.DataFrame(recovered_data, columns=column_names).astype(\\n            self._column_raw_dtypes\\n        )\\n        if not self.dataframe:\\n            recovered_data = recovered_data.to_numpy()\\n\\n        return recovered_data\\n\\n    def convert_column_name_value_to_id(self, column_name, value):\\n        \"\"\"Get the ids of the given `column_name`.\"\"\"\\n        discrete_counter = 0\\n        column_id = 0\\n        for column_transform_info in self._column_transform_info_list:\\n            if column_transform_info.column_name == column_name:\\n                break\\n            if column_transform_info.column_type == \\'discrete\\':\\n                discrete_counter += 1\\n\\n            column_id += 1\\n\\n        else:\\n            raise ValueError(f\"The column_name `{column_name}` doesn\\'t exist in the data.\")\\n\\n        ohe = column_transform_info.transform\\n        data = pd.DataFrame([value], columns=[column_transform_info.column_name])\\n        one_hot = ohe.transform(data).to_numpy()[0]\\n        if sum(one_hot) == 0:\\n            raise ValueError(f\"The value `{value}` doesn\\'t exist in the column `{column_name}`.\")\\n\\n        return {\\n            \\'discrete_column_id\\': discrete_counter,\\n            \\'column_id\\': column_id,\\n            \\'value_id\\': np.argmax(one_hot),\\n        }'}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy pandas rdt torch tqdm"
      ],
      "metadata": {
        "id": "oQiqW3OhXLgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0900a9-eeb9-4294-f1c2-071d66333c32",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting rdt\n",
            "  Downloading rdt-1.16.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from rdt) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from rdt) (1.6.1)\n",
            "Collecting Faker>=17 (from rdt)\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.3->rdt) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading rdt-1.16.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.3/69.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Faker, nvidia-cusparse-cu12, nvidia-cudnn-cu12, rdt, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed Faker-37.1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rdt-1.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZYuD3acTphV"
      },
      "outputs": [],
      "source": [
        "# Implementation of the TVAE synthesizer\n",
        "# GitHub repository: https://github.com/sdv-dev/CTGAN\n",
        "# Paper: https://arxiv.org/abs/1907.00503\n",
        "\n",
        "\"\"\"TVAE module.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import Linear, Module, Parameter, ReLU, Sequential\n",
        "from torch.nn.functional import cross_entropy\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "from transformer import DataTransformer\n",
        "\n",
        "\n",
        "class Encoder(Module):\n",
        "    \"\"\"Encoder for the TVAE.\n",
        "\n",
        "    Args:\n",
        "        data_dim (int):\n",
        "            Dimensions of the data.\n",
        "        compress_dims (tuple or list of ints):\n",
        "            Size of each hidden layer.\n",
        "        embedding_dim (int):\n",
        "            Size of the output vector.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_dim, compress_dims, embedding_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        dim = data_dim\n",
        "        seq = []\n",
        "        for item in list(compress_dims):\n",
        "            seq += [Linear(dim, item), ReLU()]\n",
        "            dim = item\n",
        "\n",
        "        self.seq = Sequential(*seq)\n",
        "        self.fc1 = Linear(dim, embedding_dim)\n",
        "        self.fc2 = Linear(dim, embedding_dim)\n",
        "\n",
        "    def forward(self, input_):\n",
        "        \"\"\"Encode the passed `input_`.\"\"\"\n",
        "        feature = self.seq(input_)\n",
        "        mu = self.fc1(feature)\n",
        "        logvar = self.fc2(feature)\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        return mu, std, logvar\n",
        "\n",
        "\n",
        "class Decoder(Module):\n",
        "    \"\"\"Decoder for the TVAE.\n",
        "\n",
        "    Args:\n",
        "        embedding_dim (int):\n",
        "            Size of the input vector.\n",
        "        decompress_dims (tuple or list of ints):\n",
        "            Size of each hidden layer.\n",
        "        data_dim (int):\n",
        "            Dimensions of the data.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim, decompress_dims, data_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        dim = embedding_dim\n",
        "        seq = []\n",
        "        for item in list(decompress_dims):\n",
        "            seq += [Linear(dim, item), ReLU()]\n",
        "            dim = item\n",
        "\n",
        "        seq.append(Linear(dim, data_dim))\n",
        "        self.seq = Sequential(*seq)\n",
        "        self.sigma = Parameter(torch.ones(data_dim) * 0.1)\n",
        "\n",
        "    def forward(self, input_):\n",
        "        \"\"\"Decode the passed `input_`.\"\"\"\n",
        "        return self.seq(input_), self.sigma\n",
        "\n",
        "\n",
        "def _loss_function(recon_x, x, sigmas, mu, logvar, output_info, factor):\n",
        "    st = 0\n",
        "    loss = []\n",
        "    for column_info in output_info:\n",
        "        for span_info in column_info:\n",
        "            if span_info.activation_fn != 'softmax':\n",
        "                ed = st + span_info.dim\n",
        "                std = sigmas[st]\n",
        "                eq = x[:, st] - torch.tanh(recon_x[:, st])\n",
        "                loss.append((eq**2 / 2 / (std**2)).sum())\n",
        "                loss.append(torch.log(std) * x.size()[0])\n",
        "                st = ed\n",
        "\n",
        "            else:\n",
        "                ed = st + span_info.dim\n",
        "                loss.append(\n",
        "                    cross_entropy(\n",
        "                        recon_x[:, st:ed], torch.argmax(x[:, st:ed], dim=-1), reduction='sum'\n",
        "                    )\n",
        "                )\n",
        "                st = ed\n",
        "\n",
        "    assert st == recon_x.size()[1]\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu**2 - logvar.exp())\n",
        "    return sum(loss) * factor / x.size()[0], KLD / x.size()[0]\n",
        "\n",
        "\n",
        "class TVAE():\n",
        "    \"\"\"TVAE.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim=128,\n",
        "        compress_dims=(128, 128),\n",
        "        decompress_dims=(128, 128),\n",
        "        l2scale=1e-5,\n",
        "        batch_size=200,\n",
        "        epochs=600,\n",
        "        loss_factor=2,\n",
        "        cuda=True,\n",
        "        verbose=False,\n",
        "    ):\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.compress_dims = compress_dims\n",
        "        self.decompress_dims = decompress_dims\n",
        "\n",
        "        self.l2scale = l2scale\n",
        "        self.batch_size = batch_size\n",
        "        self.loss_factor = loss_factor\n",
        "        self.epochs = epochs\n",
        "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Batch', 'Loss'])\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if not cuda or not torch.cuda.is_available():\n",
        "            device = 'cpu'\n",
        "        elif isinstance(cuda, str):\n",
        "            device = cuda\n",
        "        else:\n",
        "            device = 'cuda'\n",
        "\n",
        "        self._device = torch.device(device)\n",
        "\n",
        "    #random_state\n",
        "    def fit(self, train_data, discrete_columns=()):\n",
        "\n",
        "        self.transformer = DataTransformer()\n",
        "        self.transformer.fit(train_data, discrete_columns)\n",
        "        train_data = self.transformer.transform(train_data)\n",
        "        dataset = TensorDataset(torch.from_numpy(train_data.astype('float32')).to(self._device))\n",
        "        loader = DataLoader(dataset, batch_size=self.batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "        data_dim = self.transformer.output_dimensions\n",
        "        encoder = Encoder(data_dim, self.compress_dims, self.embedding_dim).to(self._device)\n",
        "        self.decoder = Decoder(self.embedding_dim, self.decompress_dims, data_dim).to(self._device)\n",
        "        optimizerAE = Adam(\n",
        "            list(encoder.parameters()) + list(self.decoder.parameters()), weight_decay=self.l2scale\n",
        "        )\n",
        "\n",
        "        self.loss_values = pd.DataFrame(columns=['Epoch', 'Batch', 'Loss'])\n",
        "        iterator = tqdm(range(self.epochs), disable=(not self.verbose))\n",
        "        if self.verbose:\n",
        "            iterator_description = 'Loss: {loss:.3f}'\n",
        "            iterator.set_description(iterator_description.format(loss=0))\n",
        "\n",
        "        for i in iterator:\n",
        "            loss_values = []\n",
        "            batch = []\n",
        "            for id_, data in enumerate(loader):\n",
        "                optimizerAE.zero_grad()\n",
        "                real = data[0].to(self._device)\n",
        "                mu, std, logvar = encoder(real)\n",
        "                eps = torch.randn_like(std)\n",
        "                emb = eps * std + mu\n",
        "                rec, sigmas = self.decoder(emb)\n",
        "                loss_1, loss_2 = _loss_function(\n",
        "                    rec,\n",
        "                    real,\n",
        "                    sigmas,\n",
        "                    mu,\n",
        "                    logvar,\n",
        "                    self.transformer.output_info_list,\n",
        "                    self.loss_factor,\n",
        "                )\n",
        "                loss = loss_1 + loss_2\n",
        "                loss.backward()\n",
        "                optimizerAE.step()\n",
        "                self.decoder.sigma.data.clamp_(0.01, 1.0)\n",
        "\n",
        "                batch.append(id_)\n",
        "                loss_values.append(loss.detach().cpu().item())\n",
        "\n",
        "            epoch_loss_df = pd.DataFrame({\n",
        "                'Epoch': [i] * len(batch),\n",
        "                'Batch': batch,\n",
        "                'Loss': loss_values,\n",
        "            })\n",
        "            if not self.loss_values.empty:\n",
        "                self.loss_values = pd.concat([self.loss_values, epoch_loss_df]).reset_index(\n",
        "                    drop=True\n",
        "                )\n",
        "            else:\n",
        "                self.loss_values = epoch_loss_df\n",
        "\n",
        "            if self.verbose:\n",
        "                iterator.set_description(\n",
        "                    iterator_description.format(loss=loss.detach().cpu().item())\n",
        "                )\n",
        "\n",
        "    #random_state\n",
        "    def sample(self, samples):\n",
        "\n",
        "        self.decoder.eval()\n",
        "\n",
        "        steps = samples // self.batch_size + 1\n",
        "        data = []\n",
        "        for _ in range(steps):\n",
        "            mean = torch.zeros(self.batch_size, self.embedding_dim)\n",
        "            std = mean + 1\n",
        "            noise = torch.normal(mean=mean, std=std).to(self._device)\n",
        "            fake, sigmas = self.decoder(noise)\n",
        "            fake = torch.tanh(fake)\n",
        "            data.append(fake.detach().cpu().numpy())\n",
        "\n",
        "        data = np.concatenate(data, axis=0)\n",
        "        data = data[:samples]\n",
        "        return self.transformer.inverse_transform(data, sigmas.detach().cpu().numpy())\n",
        "\n",
        "    def set_device(self, device):\n",
        "        \"\"\"Set the `device` to be used ('GPU' or 'CPU).\"\"\"\n",
        "        self._device = device\n",
        "        self.decoder.to(self._device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tvae = TVAE()\n",
        "\n",
        "tvae.fit(train_data, discrete_columns)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qbsZ1P9PUGro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples = tvae.sample(100)"
      ],
      "metadata": {
        "id": "DL08_G-oUV8i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}