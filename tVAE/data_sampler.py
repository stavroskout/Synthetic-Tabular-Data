# -*- coding: utf-8 -*-
"""CTGAN_data_sampler.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Nx032G5WjTNIKe6Nuly8E-31Xj3xzOWG
"""

"""DataSampler module."""

import numpy as np


class DataSampler(object):
    """DataSampler samples the conditional vector and corresponding data for CTGAN."""

    def __init__(self, data, output_info, log_frequency):
        self._data_length = len(data)

        def is_discrete_column(column_info):
            return len(column_info) == 1 and column_info[0].activation_fn == 'softmax'

        n_discrete_columns = sum([
            1 for column_info in output_info if is_discrete_column(column_info)
        ])

        self._discrete_column_matrix_st = np.zeros(n_discrete_columns, dtype='int32')

        # Store the row id for each category in each discrete column.
        # For example _rid_by_cat_cols[a][b] is a list of all rows with the
        # a-th discrete column equal value b.
        self._rid_by_cat_cols = []

        # Compute _rid_by_cat_cols
        st = 0
        for column_info in output_info:
            if is_discrete_column(column_info):
                span_info = column_info[0]
                ed = st + span_info.dim  #span_info.dim is the number of categories of the discrete column

                rid_by_cat = []
                for j in range(span_info.dim):  #For each category
                    rid_by_cat.append(np.nonzero(data[:, st + j])[0]) #np.nonzero returns the indices that correspond to nonzero values.
                self._rid_by_cat_cols.append(rid_by_cat) #So for every category a list of indices is created that matches the rows that belong in it. In the end we get a concatenation of these lists.
                #For each different column (meaning column_info in output_info as the latter contains info about all the columns) a rid_by_cat is created and the appended to _rid_by_cat_cols
                #So the ed result is a 2-D array where _rid_by_cat_cols[a][b] is a list of all rows with the a-th discrete column equal to value b
                st = ed
            else:
                st += sum([span_info.dim for span_info in column_info])
        assert st == data.shape[1]

        # Prepare an interval matrix for efficiently sample conditional vector
        max_category = max(
            [column_info[0].dim for column_info in output_info if is_discrete_column(column_info)],
            default=0,
        )

        self._discrete_column_cond_st = np.zeros(n_discrete_columns, dtype='int32')
        self._discrete_column_n_category = np.zeros(n_discrete_columns, dtype='int32')
        self._discrete_column_category_prob = np.zeros((n_discrete_columns, max_category))
        self._n_discrete_columns = n_discrete_columns
        self._n_categories = sum([
            column_info[0].dim for column_info in output_info if is_discrete_column(column_info)
        ])

        st = 0
        current_id = 0
        current_cond_st = 0
        for column_info in output_info:
            if is_discrete_column(column_info):
                span_info = column_info[0]
                ed = st + span_info.dim
                category_freq = np.sum(data[:, st:ed], axis=0) #sums the 1 values found in each category of the current attribute
                if log_frequency:
                    category_freq = np.log(category_freq + 1)
                category_prob = category_freq / np.sum(category_freq) #normalizes the values tfrom 0 to 1
                self._discrete_column_category_prob[current_id, : span_info.dim] = category_prob
                self._discrete_column_cond_st[current_id] = current_cond_st
                self._discrete_column_n_category[current_id] = span_info.dim
                current_cond_st += span_info.dim
                current_id += 1
                st = ed
            else:
                st += sum([span_info.dim for span_info in column_info])

    #sample a random category from the attribute 'discrete_column_id'
    def _random_choice_prob_index(self, discrete_column_id):
        probs = self._discrete_column_category_prob[discrete_column_id] #that is an array with 1 row and span_info.dim columns
        r = np.expand_dims(np.random.rand(probs.shape[0]), axis=1) #returns basically one value with 2 dimensions to match probs
        return (probs.cumsum(axis=1) > r).argmax(axis=1) #cumsum is the cumulative sum. Every probability is added to the previous one and as we move forward, the first time the sum exceeds r, we select the corresponding column

    def sample_condvec(self, batch):
        """Generate the conditional vector for training.

        Returns:
            cond (batch x #categories):
                The conditional vector.
            mask (batch x #discrete columns):
                A one-hot vector indicating the selected discrete column.
            discrete column id (batch):
                Integer representation of mask.
            category_id_in_col (batch):
                Selected category in the selected discrete column.
        """
        if self._n_discrete_columns == 0:
            return None

        discrete_column_id = np.random.choice(np.arange(self._n_discrete_columns), batch) #Samples randomly a total of 'batch' column ids

        cond = np.zeros((batch, self._n_categories), dtype='float32')
        mask = np.zeros((batch, self._n_discrete_columns), dtype='float32')
        mask[np.arange(batch), discrete_column_id] = 1 #For each row of the batch numbered for 0 to batch-1 it sets the corresponding column id to 1
        category_id_in_col = self._random_choice_prob_index(discrete_column_id)
        category_id = self._discrete_column_cond_st[discrete_column_id] + category_id_in_col
        cond[np.arange(batch), category_id] = 1

        return cond, mask, discrete_column_id, category_id_in_col
        ## !!! Here mask vector seems to anly be dealing with the discrete columns and not also with the categories as described in the paper !!!

    def sample_original_condvec(self, batch):
        """Generate the conditional vector for generation use original frequency."""
        if self._n_discrete_columns == 0:
            return None

        category_freq = self._discrete_column_category_prob.flatten()
        category_freq = category_freq[category_freq != 0] # removes zero values
        category_freq = category_freq / np.sum(category_freq) #category_freq now contains the probability af each category of each colun all together normilized from 0 to 1
        col_idxs = np.random.choice(np.arange(len(category_freq)), batch, p=category_freq) #makes 'batch' random choices based on category_freq distribution
        cond = np.zeros((batch, self._n_categories), dtype='float32')
        cond[np.arange(batch), col_idxs] = 1

        return cond

    def sample_data(self, data, n, col, opt):
        """Sample data from original training data satisfying the sampled conditional vector.

        Args:
            data:
                The training data.

        Returns:
            n:
                n rows of matrix data.
        """
        ## col -> discrete_column_id
        ## opt -> category_id_in_col
        if col is None:
            idx = np.random.randint(len(data), size=n) #generates n random ints between 0 and len(data)
            return data[idx]

        idx = []
        for c, o in zip(col, opt):
            idx.append(np.random.choice(self._rid_by_cat_cols[c][o])) #for all col,opt combinations given, return a row with the value opt in column col

        return data[idx]

    def dim_cond_vec(self):
        """Return the total number of categories."""
        return self._n_categories

    def generate_cond_from_condition_column_info(self, condition_info, batch):
        """Generate the condition vector."""
        vec = np.zeros((batch, self._n_categories), dtype='float32')
        id_ = self._discrete_column_matrix_st[condition_info['discrete_column_id']] #condition_info comes from convert_column_name_value_to_id of the transformer module
        id_ += condition_info['value_id']
        vec[:, id_] = 1
        return vec